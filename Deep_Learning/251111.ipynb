{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2a8460b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 12:02:55.283885: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-11 12:02:55.460753: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-11 12:02:55.543407: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-11 12:02:55.544080: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-11 12:02:55.666358: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-11 12:02:56.655373: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set to 42\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "\n",
    "# Deep Learning용 기본 import 및 seed 설정\n",
    "\n",
    "# 필요한 module import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# Random Seed를 위해서 포함\n",
    "import os\n",
    "import random\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf  \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# 시드 설정하는 함수\n",
    "def seed_everything(seed=42):\n",
    "\n",
    "    # 1. 환경변수\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    # 2. Python, Numpy\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 3. TensorFlow\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # 4. PyTorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)  # PyTorch 1.8+ 권장\n",
    "\n",
    "    print(f\"Seeds set to {seed}\")\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d7c3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "# AND, OR, XOR 게이트를 학습할 수 있는지 확인할꺼예요!\n",
    "x_data = np.array([[0,0],\n",
    "                   [0,1],\n",
    "                   [1,0],\n",
    "                   [1,1]], dtype=np.float32)\n",
    "# AND Gate\n",
    "y_data = np.array([0,0,0,1], dtype=np.float32).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc98378a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x70bc78729600>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TensorFlow 구현\n",
    "# Model 생성\n",
    "keras_model = Sequential()\n",
    "\n",
    "# Model에 Layer를 추가\n",
    "keras_model.add(Input(shape=(2,)))\n",
    "keras_model.add(Dense(units=1,\n",
    "                      activation='sigmoid'))\n",
    "# Model Compile\n",
    "keras_model.compile(optimizer=Adam(learning_rate=1e-1),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# TensorBoard callback\n",
    "log_dir = './logs/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tb_cb = TensorBoard(log_dir=log_dir,\n",
    "                    histogram_freq=1)\n",
    "\n",
    "# 학습을 진행\n",
    "keras_model.fit(x_data,\n",
    "                y_data,\n",
    "                epochs=500,\n",
    "                callbacks=[tb_cb],\n",
    "                verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b828707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습이 제대로 되었는지 확인(평가)\n",
    "\n",
    "# 평가데이터가 따로 없어요. 그래서 학습데이터로 평가해서\n",
    "# 정상적으로 학습이 되었는지 확인!\n",
    "keras_y_pred = keras_model.predict(x_data)\n",
    "keras_y_pred_class = (keras_y_pred >= 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_data,\n",
    "               keras_y_pred_class)\n",
    "# AND, OR => 1.0\n",
    "# XOR => 0.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0adc65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/20000, Loss : 0.7610647678375244\n",
      "Epoch : 2000/20000, Loss : 0.406097412109375\n",
      "Epoch : 4000/20000, Loss : 0.24944382905960083\n",
      "Epoch : 6000/20000, Loss : 0.157632514834404\n",
      "Epoch : 8000/20000, Loss : 0.09901855885982513\n",
      "Epoch : 10000/20000, Loss : 0.061659228056669235\n",
      "Epoch : 12000/20000, Loss : 0.03820893540978432\n",
      "Epoch : 14000/20000, Loss : 0.02362879179418087\n",
      "Epoch : 16000/20000, Loss : 0.014600981026887894\n",
      "Epoch : 18000/20000, Loss : 0.009020705707371235\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 구현\n",
    "\n",
    "# for TensorBoard\n",
    "log_dir = './logs/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "wirter = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Trainig Tensor(PyTorch Tensor로 변환)\n",
    "x_tensor = torch.FloatTensor(x_data)\n",
    "y_tensor = torch.FloatTensor(y_data)\n",
    "\n",
    "# Model class 정의\n",
    "class PerceptronClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2,1)  # TensorFlow의 Dense()\n",
    "    def forward(self,x):\n",
    "        # 순전파 구조(Feedforward) vs 순전파 연산(Forward Propagation)\n",
    "        # 순전파 하는 함수\n",
    "        # 우리 모델에 데이터를 넣어서 예측값을 얻어내는 연산과정\n",
    "        out = self.linear(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Model 생성\n",
    "torch_model = PerceptronClass()\n",
    "\n",
    "# Loss와 Optimizer 생성\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(torch_model.parameters(),\n",
    "                       lr=1e-3)\n",
    "\n",
    "# 훈련을 진행\n",
    "epochs=20000\n",
    "\n",
    "# 학습을 진행(backpropagation을 이용한 가중치 조절)\n",
    "torch_model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 순전파\n",
    "    y_pred = torch_model(x_tensor)\n",
    "    # Loss 계산\n",
    "    loss = criterion(y_pred, y_tensor)\n",
    "    # loss : 정답과 모델 예측값의 차이!\n",
    "\n",
    "    # 역전파를 통한 가중치 update\n",
    "    optimizer.zero_grad() # 기존 기울기 초기화\n",
    "    loss.backward()   # 기울기 역전파\n",
    "    optimizer.step()  # 가중치 update\n",
    "\n",
    "    # TensorBoard용 로그파일에 내용 기록\n",
    "    wirter.add_scalar('Loss/train',\n",
    "                      loss.item(), epoch)\n",
    "\n",
    "    # 학습이 진행되는지 확인하기 위한 출력구문\n",
    "    if epoch % 2000 == 0:\n",
    "        print(f'Epoch : {epoch}/{epochs}, Loss : {loss.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1de7b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 우리 모델을 평가해야 해요!\n",
    "torch_model.eval()\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch_y_pred = torch_model(x_tensor)\n",
    "    torch_y_pred_class = (torch_y_pred.numpy() >= 0.5).astype(int)\n",
    "\n",
    "    print(accuracy_score(y_data, torch_y_pred_class)) # 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e32311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결론적으로\n",
    "# AND, OR 이런 Gate 진리표는 1개의 Perceptron(Logistic)으로 학습이 가능\n",
    "# 그러나 XOR같은 이런 Gate의 진리표는 1개의 perceptron으로\n",
    "# 학습이 안되요!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
